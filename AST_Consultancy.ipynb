{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03921e02-cb2f-465d-b794-f80d0f5ace9a",
   "metadata": {},
   "source": [
    "# Fetching Data Using Web Scaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9863dd67-c54f-4f00-b441-8fa4c8048fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c14a05-858c-421f-b5ff-4c70633057e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a4668d4-0989-4d4a-9fe5-b61bf51d9f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "Response status code: 403\n",
      "Scraping page 2\n",
      "Response status code: 403\n",
      "Scraping page 3\n",
      "Response status code: 403\n"
     ]
    }
   ],
   "source": [
    "# Import the libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Define the base URL and the query parameters\n",
    "base_url = \"https://www.indeed.com/jobs\"\n",
    "params = {\n",
    "    \"q\": \"Python developer\", # The keyword to search for\n",
    "    \"start\": 0 # The start index for pagination (increment by 10 for each page)\n",
    "}\n",
    "\n",
    "\n",
    "# Define a function to scrape one page of results\n",
    "def scrape_page(url, params, headers):\n",
    "    # Send a GET request with the URL, parameters, and headers\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    # Check if the response status code is 200 (OK)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        # Find all the job cards in the HTML\n",
    "        job_cards = soup.find_all(\"div\", class_=\"jobsearch-SerpJobCard\")\n",
    "        # Loop through each job card\n",
    "        for job_card in job_cards:\n",
    "            # Extract the job title, company, location, and link from the job card\n",
    "            job_title = job_card.find(\"h2\", class_=\"title\").a.get(\"title\")\n",
    "            company = job_card.find(\"span\", class_=\"company\").text.strip()\n",
    "            location = job_card.find(\"div\", class_=\"location\").text.strip()\n",
    "            link = \"https://www.indeed.com\" + job_card.find(\"h2\", class_=\"title\").a.get(\"href\")\n",
    "            # Print the extracted data\n",
    "            print(f\"Job title: {job_title}\")\n",
    "            print(f\"Company: {company}\")\n",
    "            print(f\"Location: {location}\")\n",
    "            print(f\"Link: {link}\")\n",
    "            print(\"-\" * 80)\n",
    "    else:\n",
    "        # Print the response status code if not 200\n",
    "        print(f\"Response status code: {response.status_code}\")\n",
    "\n",
    "# Define the number of pages to scrape (10 results per page)\n",
    "num_pages = 3\n",
    "\n",
    "# Loop through each page\n",
    "for page in range(num_pages):\n",
    "    \n",
    "    # Define the headers with the user-agent\n",
    "    headers = {'User-Agent':'Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_1 like Mac OS X) AppleWebKit/603.1.30 (KHTML, like Gecko) Version/10.0 Mobile/14E304 Safari/602.1'}\n",
    "    \n",
    "    # Print the current page number\n",
    "    print(f\"Scraping page {page + 1}\")\n",
    "    # Scrape the current page\n",
    "    scrape_page(base_url, params, headers)\n",
    "    \n",
    "    time.sleep(random.uniform(1, 3))\n",
    "    # Increment the start parameter by 10 for the next page\n",
    "    params[\"start\"] += 10\n",
    "    # Wait for 2 seconds before scraping the next page\n",
    "    time.sleep(random.uniform(1, 3)) \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fef6ae6-489e-4866-9467-fb8da5577fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cloudscraper\n",
      "  Downloading cloudscraper-1.2.71-py2.py3-none-any.whl (99 kB)\n",
      "     ---------------------------------------- 0.0/99.7 kB ? eta -:--:--\n",
      "     ---- ----------------------------------- 10.2/99.7 kB ? eta -:--:--\n",
      "     ---- ----------------------------------- 10.2/99.7 kB ? eta -:--:--\n",
      "     ----------- -------------------------- 30.7/99.7 kB 330.3 kB/s eta 0:00:01\n",
      "     ----------------------------------- -- 92.2/99.7 kB 585.1 kB/s eta 0:00:01\n",
      "     -------------------------------------- 99.7/99.7 kB 519.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pyparsing>=2.4.7 in c:\\users\\shiva\\dataengineer_shiva_sethi_20103128\\env\\lib\\site-packages (from cloudscraper) (3.0.9)\n",
      "Requirement already satisfied: requests>=2.9.2 in c:\\users\\shiva\\dataengineer_shiva_sethi_20103128\\env\\lib\\site-packages (from cloudscraper) (2.31.0)\n",
      "Collecting requests-toolbelt>=0.9.1 (from cloudscraper)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "     ---------------------------------------- 0.0/54.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 54.5/54.5 kB 2.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shiva\\dataengineer_shiva_sethi_20103128\\env\\lib\\site-packages (from requests>=2.9.2->cloudscraper) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shiva\\dataengineer_shiva_sethi_20103128\\env\\lib\\site-packages (from requests>=2.9.2->cloudscraper) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shiva\\dataengineer_shiva_sethi_20103128\\env\\lib\\site-packages (from requests>=2.9.2->cloudscraper) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shiva\\dataengineer_shiva_sethi_20103128\\env\\lib\\site-packages (from requests>=2.9.2->cloudscraper) (2023.11.17)\n",
      "Installing collected packages: requests-toolbelt, cloudscraper\n",
      "Successfully installed cloudscraper-1.2.71 requests-toolbelt-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install cloudscraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "543fdd3f-32df-486e-99a3-73c53e56937a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "Response status code: 403\n",
      "Scraping page 2\n",
      "Response status code: 403\n",
      "Scraping page 3\n",
      "Response status code: 403\n"
     ]
    }
   ],
   "source": [
    "import cloudscraper\n",
    "\n",
    "scraper = cloudscraper.create_scraper()  # Create a Cloudscraper instance\n",
    "\n",
    "def scrape_page(url, params, headers):\n",
    "    response = scraper.get(url, params=params, headers=headers)\n",
    "    # Check if the response status code is 200 (OK)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        # Find all the job cards in the HTML\n",
    "        job_cards = soup.find_all(\"div\", class_=\"jobsearch-SerpJobCard\")\n",
    "        # Loop through each job card\n",
    "        for job_card in job_cards:\n",
    "            # Extract the job title, company, location, and link from the job card\n",
    "            job_title = job_card.find(\"h2\", class_=\"title\").a.get(\"title\")\n",
    "            company = job_card.find(\"span\", class_=\"company\").text.strip()\n",
    "            location = job_card.find(\"div\", class_=\"location\").text.strip()\n",
    "            link = \"https://www.indeed.com\" + job_card.find(\"h2\", class_=\"title\").a.get(\"href\")\n",
    "            # Print the extracted data\n",
    "            print(f\"Job title: {job_title}\")\n",
    "            print(f\"Company: {company}\")\n",
    "            print(f\"Location: {location}\")\n",
    "            print(f\"Link: {link}\")\n",
    "            print(\"-\" * 80)\n",
    "    else:\n",
    "        # Print the response status code if not 200\n",
    "        print(f\"Response status code: {response.status_code}\")\n",
    "\n",
    "# Define the number of pages to scrape (10 results per page)\n",
    "num_pages = 3\n",
    "    # Loop through each page\n",
    "for page in range(num_pages):\n",
    "    \n",
    "    # Define the headers with the user-agent\n",
    "    headers = {'User-Agent':'Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_1 like Mac OS X) AppleWebKit/603.1.30 (KHTML, like Gecko) Version/10.0 Mobile/14E304 Safari/602.1'}\n",
    "    \n",
    "    # Print the current page number\n",
    "    print(f\"Scraping page {page + 1}\")\n",
    "    # Scrape the current page\n",
    "    scrape_page(base_url, params, headers)\n",
    "    \n",
    "    time.sleep(random.uniform(1, 3))\n",
    "    # Increment the start parameter by 10 for the next page\n",
    "    params[\"start\"] += 10\n",
    "    # Wait for 2 seconds before scraping the next page\n",
    "    time.sleep(random.uniform(1, 3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "095fbd93-46c7-43f8-96b2-7c3cb1143469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting playwright\n",
      "  Downloading playwright-1.40.0-py3-none-win_amd64.whl.metadata (3.6 kB)\n",
      "Collecting greenlet==3.0.1 (from playwright)\n",
      "  Downloading greenlet-3.0.1-cp310-cp310-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting pyee==11.0.1 (from playwright)\n",
      "  Downloading pyee-11.0.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\shiva\\dataengineer_shiva_sethi_20103128\\env\\lib\\site-packages (from pyee==11.0.1->playwright) (4.7.1)\n",
      "Downloading playwright-1.40.0-py3-none-win_amd64.whl (29.3 MB)\n",
      "   ---------------------------------------- 0.0/29.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/29.3 MB 1.4 MB/s eta 0:00:22\n",
      "   ---------------------------------------- 0.2/29.3 MB 2.9 MB/s eta 0:00:11\n",
      "    --------------------------------------- 0.5/29.3 MB 3.5 MB/s eta 0:00:09\n",
      "    --------------------------------------- 0.6/29.3 MB 3.2 MB/s eta 0:00:09\n",
      "    --------------------------------------- 0.6/29.3 MB 3.2 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.9/29.3 MB 3.4 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 1.1/29.3 MB 3.5 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 1.1/29.3 MB 3.2 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 1.2/29.3 MB 3.1 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 1.4/29.3 MB 3.1 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.6/29.3 MB 3.1 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 1.8/29.3 MB 3.3 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 2.0/29.3 MB 3.3 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 2.1/29.3 MB 3.3 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 2.3/29.3 MB 3.5 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 2.4/29.3 MB 3.4 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 2.7/29.3 MB 3.5 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 2.9/29.3 MB 3.5 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 3.0/29.3 MB 3.5 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 3.2/29.3 MB 3.5 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 3.4/29.3 MB 3.6 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 3.6/29.3 MB 3.6 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 3.9/29.3 MB 3.7 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 4.1/29.3 MB 3.7 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 4.4/29.3 MB 3.8 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 4.6/29.3 MB 3.8 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 4.8/29.3 MB 3.9 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 5.0/29.3 MB 3.9 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 5.2/29.3 MB 3.9 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 5.5/29.3 MB 3.9 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 5.7/29.3 MB 4.0 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 5.9/29.3 MB 4.0 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 6.2/29.3 MB 4.0 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 6.5/29.3 MB 4.0 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 6.6/29.3 MB 4.0 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 6.7/29.3 MB 4.0 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 6.8/29.3 MB 3.9 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 6.9/29.3 MB 3.9 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 7.1/29.3 MB 3.8 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 7.2/29.3 MB 3.8 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 7.4/29.3 MB 3.8 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 7.6/29.3 MB 3.8 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 7.8/29.3 MB 3.8 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 7.8/29.3 MB 3.8 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 7.9/29.3 MB 3.7 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 8.0/29.3 MB 3.7 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 8.1/29.3 MB 3.6 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 8.1/29.3 MB 3.6 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 8.3/29.3 MB 3.6 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 8.4/29.3 MB 3.6 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 8.6/29.3 MB 3.6 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 8.8/29.3 MB 3.6 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 9.1/29.3 MB 3.6 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 9.3/29.3 MB 3.7 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 9.5/29.3 MB 3.7 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 9.7/29.3 MB 3.7 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 9.9/29.3 MB 3.7 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 10.1/29.3 MB 3.7 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 10.3/29.3 MB 3.7 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 10.6/29.3 MB 3.7 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 10.8/29.3 MB 3.8 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 11.0/29.3 MB 3.8 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 11.2/29.3 MB 3.8 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 11.4/29.3 MB 3.9 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 11.7/29.3 MB 3.9 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 11.9/29.3 MB 3.9 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 12.2/29.3 MB 3.9 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 12.4/29.3 MB 4.0 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 12.6/29.3 MB 4.0 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 12.8/29.3 MB 4.0 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 13.0/29.3 MB 4.0 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 13.3/29.3 MB 4.0 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 13.5/29.3 MB 4.0 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 13.7/29.3 MB 4.0 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 13.9/29.3 MB 4.0 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 14.1/29.3 MB 4.0 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 14.2/29.3 MB 3.9 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 14.3/29.3 MB 3.9 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 14.6/29.3 MB 3.9 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 14.8/29.3 MB 3.9 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 15.0/29.3 MB 3.9 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 15.2/29.3 MB 3.9 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 15.4/29.3 MB 3.9 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 15.6/29.3 MB 3.9 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 15.8/29.3 MB 3.9 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 16.0/29.3 MB 3.9 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 16.2/29.3 MB 3.9 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 16.4/29.3 MB 3.8 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 16.7/29.3 MB 3.8 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 16.9/29.3 MB 3.9 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 17.1/29.3 MB 3.9 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 17.3/29.3 MB 4.0 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 17.5/29.3 MB 4.0 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 17.7/29.3 MB 4.1 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 17.8/29.3 MB 4.0 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 18.1/29.3 MB 4.0 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 18.2/29.3 MB 4.2 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 18.5/29.3 MB 4.3 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 18.7/29.3 MB 4.3 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 18.8/29.3 MB 4.3 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 19.0/29.3 MB 4.3 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 19.2/29.3 MB 4.3 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 19.4/29.3 MB 4.3 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 19.6/29.3 MB 4.3 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 19.9/29.3 MB 4.3 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 20.1/29.3 MB 4.3 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 20.3/29.3 MB 4.3 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 20.4/29.3 MB 4.3 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 20.6/29.3 MB 4.2 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 20.9/29.3 MB 4.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 21.1/29.3 MB 4.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 21.3/29.3 MB 4.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 21.6/29.3 MB 4.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 21.8/29.3 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 22.1/29.3 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 22.2/29.3 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 22.4/29.3 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 22.7/29.3 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 22.9/29.3 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 23.1/29.3 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 23.3/29.3 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 23.4/29.3 MB 4.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 23.7/29.3 MB 4.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 23.8/29.3 MB 4.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 23.9/29.3 MB 4.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 24.0/29.3 MB 4.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 24.1/29.3 MB 4.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 24.1/29.3 MB 4.0 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 24.2/29.3 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 24.4/29.3 MB 4.0 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 24.6/29.3 MB 4.0 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 24.9/29.3 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 25.1/29.3 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 25.3/29.3 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 25.5/29.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 25.7/29.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 25.8/29.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 26.1/29.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 26.3/29.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 26.5/29.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 26.7/29.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 27.0/29.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 27.3/29.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 27.5/29.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 27.7/29.3 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 27.9/29.3 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 28.1/29.3 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 28.4/29.3 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 28.6/29.3 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  28.8/29.3 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.1/29.3 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.3/29.3 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.3/29.3 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.3/29.3 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.3/29.3 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.3/29.3 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 29.3/29.3 MB 3.8 MB/s eta 0:00:00\n",
      "Downloading greenlet-3.0.1-cp310-cp310-win_amd64.whl (287 kB)\n",
      "   ---------------------------------------- 0.0/287.9 kB ? eta -:--:--\n",
      "   ---------------------------------------  286.7/287.9 kB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 287.9/287.9 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading pyee-11.0.1-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: pyee, greenlet, playwright\n",
      "Successfully installed greenlet-3.0.1 playwright-1.40.0 pyee-11.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install playwright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "746b0cad-9f62-46fa-a2ce-fd0ad0e8ead0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'playwright.chromium'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplaywright\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchromium\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m async_playwright\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Create an async function to initialize the Playwright browser\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minit\u001b[39m():\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'playwright.chromium'"
     ]
    }
   ],
   "source": [
    "from playwright.chromium import async_playwright\n",
    "\n",
    "# Create an async function to initialize the Playwright browser\n",
    "async def init():\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch()\n",
    "        context = await browser.new_context()\n",
    "        page = await context.new_page()\n",
    "        # Now you can use 'page' for scraping\n",
    "\n",
    "# Run the initialization function\n",
    "init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "106fbeaf-9197-4439-9276-e3276ae9ff16",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'playwright.chromium'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplaywright\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchromium\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m playwright\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscrape_page\u001b[39m(url, params, headers):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m playwright\u001b[38;5;241m.\u001b[39mchromium\u001b[38;5;241m.\u001b[39mlaunch() \u001b[38;5;28;01mas\u001b[39;00m p:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'playwright.chromium'"
     ]
    }
   ],
   "source": [
    "from playwright.chromium import playwright\n",
    "\n",
    "def scrape_page(url, params, headers):\n",
    "    with playwright.chromium.launch() as p:\n",
    "        browser = p.chromium.launch()\n",
    "        page = browser.new_page()\n",
    "        page.goto(url)\n",
    "\n",
    "        # Wait for job cards to load dynamically\n",
    "        job_cards = page.wait_for_selector(\".jobsearch-SerpJobCard\")\n",
    "\n",
    "        for job_card in job_cards:\n",
    "            # Extract data using Playwright's methods\n",
    "            job_title = job_card.text_content(\".title\")\n",
    "            company = job_card.text_content(\".company\")\n",
    "            location = job_card.text_content(\".location\")\n",
    "            link = job_card.get_attribute(\"href\")\n",
    "            # Print the extracted data\n",
    "            print(f\"Job title: {job_title}\")\n",
    "            print(f\"Company: {company}\")\n",
    "            print(f\"Location: {location}\")\n",
    "            print(f\"Link: {link}\")\n",
    "            print(\"-\" * 80)\n",
    "    \n",
    "        print(f\"Response status code: {response.status_code}\")\n",
    "# Define the number of pages to scrape (10 results per page)\n",
    "num_pages = 3\n",
    "    # Loop through each page\n",
    "for page in range(num_pages):\n",
    "    \n",
    "    # Define the headers with the user-agent\n",
    "    headers = {'User-Agent':'Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_1 like Mac OS X) AppleWebKit/603.1.30 (KHTML, like Gecko) Version/10.0 Mobile/14E304 Safari/602.1'}\n",
    "    \n",
    "    # Print the current page number\n",
    "    print(f\"Scraping page {page + 1}\")\n",
    "    # Scrape the current page\n",
    "    scrape_page(base_url, params, headers)\n",
    "    \n",
    "    time.sleep(random.uniform(1, 3))\n",
    "    # Increment the start parameter by 10 for the next page\n",
    "    params[\"start\"] += 10\n",
    "    # Wait for 2 seconds before scraping the next page\n",
    "    time.sleep(random.uniform(1, 3)) \n",
    "browser.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d23e34f-fb06-4791-87a3-2ab13c712f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
